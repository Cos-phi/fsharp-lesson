---
title: "第三回 トリグラムのインデクサ、ToyIndを作ろう"
layout: page
---

大規模な全文検索のためのインデクサだけれど仕様が簡単になるようにいろいろ制約はある、ToyIndを作ろう。

## 01. 全文検索入門

全文検索システムとは、大量のファイルがあって、その中から特定の単語やフレーズなどが含まれているファイルや行を高速で探すソフトウェアの事です。
Luceneやそれの上に作られたElasticsearchなどが有名です。

文字を検索するだけならファイルを順番に開いて先頭から文字を探していけば良いのですが、
これでは全ファイルサイズに比例した時間がかかってしまいます。
そこで全文検索システムというと、普通はインデックスと呼ばれる仕組みで、全ファイルをなめずに検索を可能にするものを指します。

逆に言うと、データが多くなければ単なるgrepになってしまうので、
全文検索システムというと対象となるファイルやデータが巨大である事が前提となります。

### インデックスとトリグラム

例えば「print」という単語で検索する事を考えます。
ファイルが20万ファイルあったとして、一つのファイルを検索するのに0.05秒かかるとすると、1万秒もかかってしまいます。
ですが、printという単語が入っているファイルは実際はもっとずっと少ない、例えば100ファイルとかだった場合、5秒程度で済む事になります。
この、目的の単語が含まれているファイルの数は全体に比べて少ない、という事に着目したのが、インデックスのアイデアとなります。

ですが、単純にすべての単語に対してその単語が含まれているファイルの一覧を作る場合、
例えばprintlnなどのように他の単語の中に入っている単語をどう扱うか、という問題が出てきます。
printlnという単語で調べれば引っかかるけれど、検索としてはprintで検索しても引っかかって欲しい。

そこでより単純に、n-gramという方法でインデックスを作るのが一般的です。
例えばn=3の場合をトリグラムと呼び、この第三回で作るものもトリグラムの予定なのでトリグラムの説明をしましょう。

printlnという単語があったとします。
これを3文字ずつに分割してインデックスを作る、というのがトリグラムのアイデアです。

具体例を挙げましょう。hoge.txtというファイルにprintlnという単語があったとします。
そうしたら、pri, rin, int, tlnに分けて、それぞれに対してhoge.txtにあったぞ、という情報を記録します。

printという単語を検索する場合、最初のpriのインデックスを引いて対象のファイルを絞り込み、あとは1ファイルずつ開いて検索していきます。
当然priが入っているがprintが入ってないファイル、例えばpriorityとか入っているファイルも検索の対象になってしまいますが、
少し考えれば変に偏る特殊なトリグラムを除けばかなり絞れる事が分かると思います（ユニフォームに分布してて大文字と小文字を区別して数字も入れると何分の一に絞れそうか計算してみてください）。

一般的にはn-gramのインデックスはunigram、bigramを用意して、さらに必要だったらtrigramくらいを用意するのが一般的ですが、
この第三回では単純化のためにトリグラムだけのインデックスを作る事にします。
プロジェクトの名前はToyIndとしましょう。

trigramでは2文字や1文字では検索出来ない事になりますが、
そこは勉强目的のおもちゃなので3文字以上の単語しか検索出来ないと割り切ります。

### 基本的な前提と仕様

このシリーズは基本的には「学びの少ない機能は徹底的に削る事で学習の費用対効果を最大にする」というコンセプトで、
なるべくいろいろな事を割り切るようにしています。

ですが、全文検索の説明でも言ったように、インデクサは規模が小さいとただのgrepで十分なので何を作っているのか意味がわかりません。
そこで、ToyIndは対象となるファイル数はかなり多いとします。
想定しているのはLinuxのカーネルやWebKitなどの大規模なオープンソースのコードを対象にしようかな、と思っていますが、
英語主体で取り回しが大変なほどの規模じゃない対象で入手が簡単なものだったらなんでも良いとは思っています。
(別に自然言語でも良いのですが、Wikipediaは経験上少し大きすぎてファイルを持ってきたり展開するのが大変なので、もうちょっと小さい手頃なのがいいかな、とは思っている)。

また前提として、すごく大きなファイルが混じっていたりはしない、という事にします。一つのファイルを開いて先頭から調べるのはそれほど時間はかからない、という想定。
中身はだいたい英語だが英語以外も混ざっている、という対象とします。

トリグラムの対象となる文字としては、`[a-z], [A-Z], [0-9]` のトリグラムをインデックスにする事にし、それ以外の文字はインデックスには含めません。

インデクサは最初に全部のインデックスを作り、そこから新しくドキュメントが追加されたりはしないとします。

実際の具体的な仕様は実装を進めていく中で解説を追加していきます。

### ToyIndの基本構成

ToyIndは大きく２つの機能からなります。

- ファイル名からidへのマップ、及びidからファイル名へのマップ（文書内ではファイルインデックスと呼ぶ）
- トリグラムからid listへのマップ（トリグラムインデックスと呼ぶ）

idはUInt64。

上記２つの機能があった時、ある単語を検索するのは、以下の3ステップで行う事が出来ます。

- トリグラムからファイルidを取り出す
- ファイルidからファイルパスを取り出す
- ファイルを開いて検索

そこで、この第三回ではファイルインデックスとトリグラムインデックスを様々な方法で実装しては比較していく、
というのが基本的な作業となります。

最初はこれらを手抜きで実装して全体を動かし、それで規模を増やすとどういう問題が出てくるのかを見る事から始めます。

### 初期の実装方針

ファイルインデックスもトリグラムインデックスも、それぞれ独立して実装出来て、かなり実装の選択肢も多く時間をかけて実装が出来ます。
そこでこうしたそれぞれがそれなりに大きなシステムを作る場合、
進め方にはいくつかの自由度があります。

今回はなるべく早く全体を結合して動かし、そのあと全体を動かしつつ個々のモジュールを改善していくのを目指しましょう。

{% capture evodev %}
**Big Bang IntegrationとEvolutionary Delivery**  

それぞれのモジュールをバラバラに作りこんで、最後にえいっとインテグレートするのをビッグバンインテグレーションと言います。
一方でなるべく早くインテグレーションを行い、それを継続的に更新していくのをevolutionary deliveryと呼びます。

ある程度の規模になるとevolutionary deliveryを行うメリットがとても強くなるので、
なるべくプロジェクト開発も早期のインテグレーション、早期のイテレーションを目指すのが良いでしょう。
現実では組織の壁などでなかなか早期のインテグレーションが難しい事もあるので、
かなり意図的にプロジェクトを進めないとそうはなってくれない事も多くあります。

なるべく早く結合するといっても個々のモジュールが動いている必要はあり、
それらを動かすのもそれなりに大変な作業になります。
そこで実装する時には、「なるべく簡単にハリボテを作るには、どういうハリボテにするのが良いか？」という事を頑張って考えていくとともに、「最初に全体を動かすにはどこから進めていくのが良いか？」という事を考えていく必要もあります。

この第三回ではこの辺の事を考えるのは自分の作業になってしまいますが、
そうした視点で最初に作りたいと説明したものと実際に作るものの違いなどを見ていくと、この辺の努力が分かるかもしれません。
{% endcapture %}
{% include myquote.html body=evodev %}

## 02. 全部のファイルを開いて検索、を実装する

最初はインデックス無しで検索するコードを書いてみます。
これを基本として他の方法と比較していきます。

### 最初に作るものの概要

単語とディレクトリを指定すると、そのディレクトリ以下のファイルを開いて単語を探し、単語があったら、「パス名:その行」という表示をするプログラムを作ります。
正規表現の無いgrepのようなものですね。

例えば以下のような出力です。

```
./test_data/ZipSourceCodeReading/Write.kt:        DataOutputStream(BufferedOutputStream(FileOutputStream(postIndexFile))).use {
```

また、拡張子でテキストっぽく無いものはスキップするようにします。具体的には `.png` とか `.jpg` とかです。


### プロジェクトの作成と基本的なコードを書く

まずプロジェクトとしては第二回のToyRelの時と同様、ToyIndという名前でsourcesの下に作ります。
ブランチとしてはtoyindでいいでしょう。

対象とするディレクトリの指定はとりあえずグローバル変数かなにかに書いておくのが良いと思います。
Scratch.fsxからもProgram.fsからも出来る感じにしておいてください。

まずは指定ディレクトリの下のファイルのすべてに対して、一行ずつ読んでマッチするか調べるのがいいと思います。

ファイルやディレクトリを操作するには、DirectoryInfoやStreamReaderを使っても良いのですが、
スクリプト的にF#を使っている時はFileやDirectoryを使う方がいいでしょう。

この辺は [Common I/O Tasks - Microsoft Learn](https://learn.microsoft.com/en-us/dotnet/standard/io/common-i-o-tasks)が良く書かれています。

今回だったら、

- [How to: Enumerate directories and files](https://learn.microsoft.com/en-us/dotnet/standard/io/how-to-enumerate-directories-and-files)
- [File.ReadLines Method (System.IO)](https://learn.microsoft.com/en-us/dotnet/api/system.io.file.readlines?view=net-6.0#system-io-file-readlines%28system-string%29)

あたりが良いでしょう。

{% capture stream_pipe %}
**ストリームとパイプライン**  

F#はパイプラインを使うのが便利な言語で、皆もパイプライン演算子をここまで使ってきた事でしょう。

パイプラインと組み合わせるのに都合の良いデータ構造としてストリームがあります。F#で言う所のseqやlistですね。
いろいろな機能をストリームとして返すと、いろいろな演算が使えて便利です。

例えば今回のように、ある特定のディレクトリ以下の全ファイルに対してなにかをやりたい、としたとします。
その時に、もし.NETにDirectoryInfoしかそれ系のAPIが無かった場合。
DirectoryInfoでは以下のような感じでそのディレクトリの直下にあるディレクトリの一覧やファイルの一覧が得られます。

```
let di = DirectoryInfo("./")
di.EnumerateDirectories()
di.EnumerateFiles()
```

これを使えば、一番上のディレクトリから始めて、まず自身のディレクトリ内のファイルを処理したあとに、自身の直下のディレクトリそれぞれに対して再帰的に同じ事をする、というコードを書く事が出来ますし、
何も考えなければそう書く人は多いでしょう。

でも少し切り口を変えて、指定されたディレクトリの下の全ファイルをseqとして返すような関数を作り、それを使うように書くと、
そうした再帰のコードの中にロジックが埋め込まれて再利用しづらいものよりも、ずっと見通しも良く書けて、
他の所でも再利用出来たりします。

このように、問題を分割する時にseqを返す関数とそれに対してmapしたりfilterしたりといった事で処理する部分に分ける、
というのは探してみるとすごく多くの問題に対して出来るものです。
再帰やループで書きたくなるような問題を前にした時は、
少し「ストリームにする事でアクション的な処理を外に出せないかな？」と考えてみるのは有益です。

FileやDirectory系のAPIはFileInfoやDirectoryInfoに比べてだいぶ最近に書かれたものなので、そうした視点で見るといろいろと参考になる事も多いと思います。

なお、ストリームに関しての処理を探したい時は、まず[Choosing between collection functions · F# for Fun and Profit](https://swlaschin.gitbooks.io/fsharpforfunandprofit/content/posts/list-module-functions.html)から探してみて、
これで見つからない時にはじめて[Seq (FSharp.Core)](https://fsharp.github.io/fsharp-core-docs/reference/fsharp-collections-seqmodule.html)などを探すのが良いと思います。
最初に後者のドキュメントや適当にぐぐったものを見てもなかなか欲しいものが見つからないので、まずFun and Profitの方を見るのがコツです。

{% endcapture %}
{% include myquote.html body=stream_pipe %}

### テストデータにfparsecのソースを試してみる

一番簡単な全文検索のプログラムが出来たので、これで様々なサイズのファイル群を検索してみてどうなるか見てみましょう。

まずは比較的小さな規模として、FParsecのコードなど検索してみましょう。
githubからコードを取得し、特定の場所に置きます。

とりあえずToyIndのディレクトリの下にtest_targetというディレクトリを掘り、そこに置く事にします。
つまり `souces/ToyInd/test_target/fparsec` というディレクトリの下にfparsecのコードを置く感じですね。

test_target以下は.gitignoreに加えてコミットしないようにしておいてください。
また、検索の対象としては.gitなどの不要なディレクトリは削除しておいてください。

### 基本的な計測を行う

検索対象を置いたら、
まずファイル数や行数をなんとなく調べておきます。

```
$ find . type -f | wc -l
     175

$ find . type -f | xargs wc -l
...
   74443 total

$ du -h
...
11M
```

という事で、175ファイル、74K行、11MBくらいのようです。
timeコマンドで時間を図っていましょう。
pipe3という単語をagやgrepで調べてみます。

Mac版だとgrepに `-R` オプションが使えますが、これは環境によっては使えないかもしれないので他の方法で調べてみてください。

```
$ time ag pipe3
...
ag pipe3  0.02s user 0.02s system 99% cpu 0.040 total

$ time grep -R pipe3
...
grep -R pipe3  0.16s user 0.01s system 99% cpu 0.173 total
```

agだと20msec, grepだと160msecくらいでしょうか。

メモリ使用量も測るバージョンのtimeが `/usr/bin/time` の方にあるのが普通です（何もつけないtimeはshの組み込みコマンドだったりする）。
自分の手元のMacだと`-l`のオプションを使う事でメモリ使用量が測れるようです。

```
$ /usr/bin/time -l ag pipe3
...
        0.03 real         0.01 user         0.02 sys
             3727360  maximum resident set size
                   0  average shared memory size
                   0  average unshared data size
                   0  average unshared stack size
                2984  page reclaims
                  26  page faults
                   0  swaps
                   0  block input operations
                   0  block output operations
                   0  messages sent
                   0  messages received
                   0  signals received
                  10  voluntary context switches
                 160  involuntary context switches
            76502781  instructions retired
            57790386  cycles elapsed
             3231744  peak memory footprint

$ /usr/bin/time -l grep -R pipe3
...
        0.20 real         0.15 user         0.01 sys
             1396736  maximum resident set size
                   0  average shared memory size
                   0  average unshared data size
                   0  average unshared stack size
                 471  page reclaims
                   0  page faults
                   0  swaps
                   0  block input operations
                   0  block output operations
                   0  messages sent
                   0  messages received
                   0  signals received
                 251  voluntary context switches
                  12  involuntary context switches
          1560448993  instructions retired
           657863973  cycles elapsed
              974848  peak memory footprint
```

とりあえずpeak memory footprintに相当するメモリ量と、realの時間を計測する事にしましょう。
単位は好きにしてください。

この/usr/bin/timeのアウトプットは使っているOSで結構変わる所と思います。
Linux系列だとフォーマットを指定したり出来るはず。
そういう機能が無い場合は適当なシェルスクリプトなどでrealの時間とメモリ量を抜き出すスクリプトを作ってください。

出力としてはcsvでいいでしょう。
以下のような感じでためていける感じにしたい。

```
label, time, memory
fparsec_ag, 0.03, 3231744
fparsec_grep, 0.20, 974848
```

同様に、上で書いたfsでの検索の時間なども調べて時間を教えて下さい。
調べる時はReleaseモード、つまり `dotnet run -c Release` で調べるのを忘れないように。

dotnetのメモリが上記のコマンドでいい感じに測れるか分からないので、ここまでやってみた人は結果を教えて下さい。
もし目的の数値が測れていないようならBenchmarkDotNet使うように変更します。

### 規模の違うデータセットをいくつか用意する

簡単に持ってこれて取り回しが大変なほどはでかく無い程度の大きなデータセットを追加する。

- fsharpのコンパイラ等 [dotnet/fsharp: The F# compiler, F# core library, F# language service, and F# tooling integration for Visual Studio](https://github.com/dotnet/fsharp)
- [mongodb/mongo: The MongoDB Database](https://github.com/mongodb/mongo)

| 名前 | ファイル数 | 行数 | duのバイナリサイズ | grepの時間 |
| ---- | ---- | ---- | ---- | ---- |
| fparsec | 175 | 74443 |  11M | 0.22 |
| fsharp | 10452 | 442042 | 127M | 2.57 |
| mongo | 37155 | 534676 | 573M | 12.07 |

他にllvm、Chromium、Linuxカーネルあたりとかどうだろう。誰か調べて表に追記したりリンク足したりしてください。
2〜3GBくらいのが欲しい気はする。

またこれらのデータセットに検索を試す手頃な単語も調べておいてくれると。
だいたい数件程度のヒットがあるようなのが理想ですが、あまり多すぎなければOKです（consoleへの出力の時間が問題になるようなのは測りたい事が測れないので）。

fparsecならattempt、fsharpならgenerics、mongoならpagingとかでどうでしょう？

## 03. ファイルインデックスをオンメモリで実装してみる

とりあえず各行にパスが書いてあるテキストファイルを作り、オンメモリに一度読み込む。

## 04. トリグラムのインデックスを作る

トリグラムをパスにしたindex.datみたいなファイルを作る。
まずは一行一idで。

## いくつかの規模で検索してみる

用意したデータセットに対して、全部開く検索と時間や使用メモリなどを比較する。
ついでにインデックスのサイズも記録しておく。

## ファイル名とidのindexをもう少し真面目に作る

## リストをdelta listにする

## バイナリにする